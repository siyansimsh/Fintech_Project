{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50530a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 1. 載入資料\n",
    "# 注意：Logistic Regression 需要標準化後的資料 (scaled)，樹模型通常不需要\n",
    "# 為了簡化流程，我們統一使用「原始資料」訓練樹模型，\n",
    "# 並在程式中為 Logistic Regression 建立一個 Pipeline (自動包含標準化)\n",
    "file_path = 'uci_default_cleaned.csv' \n",
    "try:\n",
    "    df = pd.read_csv(file_path)\n",
    "except FileNotFoundError:\n",
    "    print(f\"錯誤：找不到檔案 {file_path}\")\n",
    "    exit()\n",
    "\n",
    "target = 'default payment next month'\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]\n",
    "\n",
    "# 2. 切分資料\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 模型 1: Logistic Regression (LR)\n",
    "# ---------------------------------------------------------\n",
    "print(\"正在訓練 Logistic Regression...\")\n",
    "from sklearn.pipeline import Pipeline\n",
    "# LR 對特徵縮放敏感，所以我們用 Pipeline 把 StandardScaler 包進去\n",
    "lr_model = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', LogisticRegression(class_weight='balanced', random_state=42, max_iter=1000))\n",
    "])\n",
    "lr_model.fit(X_train, y_train)\n",
    "joblib.dump(lr_model, 'lr_model.pkl')\n",
    "print(\"-> 已儲存 lr_model.pkl\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 模型 2: Random Forest (RF)\n",
    "# ---------------------------------------------------------\n",
    "print(\"正在訓練 Random Forest...\")\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=200, \n",
    "    max_depth=10,\n",
    "    class_weight='balanced', \n",
    "    random_state=42, \n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_model.fit(X_train, y_train)\n",
    "joblib.dump(rf_model, 'rf_model.pkl')\n",
    "print(\"-> 已儲存 rf_model.pkl\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 模型 3: XGBoost (XGB)\n",
    "# ---------------------------------------------------------\n",
    "print(\"正在訓練 XGBoost...\")\n",
    "# XGBoost 的 scale_pos_weight 用來處理不平衡 (類似 class_weight)\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1) #\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    scale_pos_weight=ratio,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "xgb_model.fit(X_train, y_train)\n",
    "joblib.dump(xgb_model, 'xgb_model.pkl')\n",
    "print(\"-> 已儲存 xgb_model.pkl\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 儲存共用資料\n",
    "# ---------------------------------------------------------\n",
    "# 儲存特徵名稱\n",
    "joblib.dump(X.columns.tolist(), 'feature_names.pkl')\n",
    "\n",
    "# 儲存參考數據 (用於同儕比較)\n",
    "reference_data = X_test.sample(n=1000, random_state=42)\n",
    "reference_data.to_csv('reference_data.csv', index=False)\n",
    "\n",
    "print(\"\\n全部完成！所有模型已儲存。\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
